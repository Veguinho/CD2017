{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "    \n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Big Mac'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "92\n",
      "% sim 0.6933333333333334\n",
      "% nao 0.30666666666666664\n",
      "Total de palavras 1156\n",
      "Total de palavras relevantes 673\n",
      "Total de palavras não relevantes 483\n",
      "['sim', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'não', 'não', 'sim', 'não', 'não', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'não', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'sim', 'não', 'não', 'não', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'não', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'não', 'sim']\n",
      "['sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'não', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'sim', 'não', 'sim']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "listaR = []\n",
    "palavrasSim = []\n",
    "palavrasNao = []\n",
    "#Limpa a planilha com palavras usáveis\n",
    "planilhaTREI = pd.read_excel('Big Mac TREINAMENTO.xlsx',sep=',')\n",
    "planilhaTEST = pd.read_excel('Big Mac TESTE.xlsx',sep=',')\n",
    "for i in range(len(planilhaTREI.Treinamento)):\n",
    "    linhaX = planilhaTREI.Treinamento[i].lower()\n",
    "    linhaX = linhaX.split()\n",
    "    for k in range(len(linhaX)):\n",
    "        for punctuation in string.punctuation:\n",
    "            linhaX[k] = linhaX[k].replace(punctuation, '')\n",
    "        linhaX[k] = linhaX[k].replace('—', '')\n",
    "        linhaX[k] = linhaX[k].replace('rt', '')\n",
    "        if planilhaTREI.Relevância[i] == 'sim':\n",
    "            palavrasSim.append(linhaX[k])\n",
    "        elif planilhaTREI.Relevância[i] == 'não':\n",
    "            palavrasNao.append(linhaX[k])\n",
    "    while '' in linhaX:\n",
    "        linhaX.remove('')\n",
    "    planilhaTREI.Treinamento[i] = linhaX\n",
    "\n",
    "#Remove '' da lista de palavras a serem contadas    \n",
    "while '' in palavrasSim:\n",
    "    palavrasSim.remove('')\n",
    "\n",
    "while '' in palavrasNao:\n",
    "    palavrasNao.remove('')\n",
    "    \n",
    "#Calcula quantas vezes aparece Sim ou Nao    \n",
    "for i in planilhaTREI.Relevância:\n",
    "    if i == 'sim':\n",
    "        listaR.append(i)\n",
    "    if i == 'não':\n",
    "        listaR.append(i)\n",
    "numeroSim = 0\n",
    "numeroNao = 0\n",
    "for j in listaR:\n",
    "    if j == 'sim':\n",
    "        numeroSim += 1\n",
    "    if j == 'não':\n",
    "        numeroNao += 1\n",
    "        \n",
    "#Conta cada palavra da lista\n",
    "contandoSim = [[x,palavrasSim.count(x)] for x in set(palavrasSim)]\n",
    "contandoNao = [[y,palavrasNao.count(y)] for y in set(palavrasNao)]\n",
    "\n",
    "\n",
    "#Calcula quantas palavras existem no espaço amostral\n",
    "wordsNumber = 0\n",
    "numeroPalavrasSim = 0\n",
    "numeroPalavrasNao = 0\n",
    "for k in range(len(contandoSim)):\n",
    "    wordsNumber = wordsNumber + contandoSim[k][1]\n",
    "    numeroPalavrasSim = numeroPalavrasSim + contandoSim[k][1]\n",
    "for k in range(len(contandoNao)):\n",
    "    wordsNumber = wordsNumber + contandoNao[k][1]\n",
    "    numeroPalavrasNao = numeroPalavrasNao + contandoNao[k][1]\n",
    "\n",
    "\n",
    "#print(contandoSim)\n",
    "#print('.')\n",
    "#print(contandoNao)\n",
    "print(numeroSim)\n",
    "print(numeroNao)\n",
    "print('% sim',numeroSim/300)\n",
    "print('% nao',numeroNao/300)\n",
    "print('Total de palavras', len(contandoSim)+len(contandoNao))\n",
    "print('Total de palavras relevantes', len(contandoSim))\n",
    "print('Total de palavras não relevantes', len(contandoNao))\n",
    "\n",
    "print(listaR)\n",
    "#planilhaTEST\n",
    "\n",
    "#Limpando a nova planilha\n",
    "for i in range(len(planilhaTEST.Teste)):\n",
    "    linhaX = planilhaTEST.Teste[i].lower()\n",
    "    linhaX = linhaX.split()\n",
    "    for k in range(len(linhaX)):\n",
    "        for punctuation in string.punctuation:\n",
    "            linhaX[k] = linhaX[k].replace(punctuation, '')\n",
    "        linhaX[k] = linhaX[k].replace('—', '')\n",
    "        linhaX[k] = linhaX[k].replace('rt', '')\n",
    "    while '' in linhaX:\n",
    "        linhaX.remove('')\n",
    "    planilhaTEST.Teste[i] = linhaX\n",
    "    \n",
    "#Calcular a probabilidade de uma frase ser relevante na planilha teste\n",
    "probAllSIM = []\n",
    "y = 1\n",
    "for i in range(len(planilhaTEST.Teste)):\n",
    "    probLinha = []\n",
    "    for k in range(len(planilhaTEST.Teste[i])):\n",
    "        probX = 0\n",
    "        for j in range(len(contandoSim)):\n",
    "            if contandoSim[j][0] == planilhaTEST.Teste[i][k]:\n",
    "                probX = ((contandoSim[j][1]+1)/(len(contandoSim)+(len(contandoSim)+len(contandoNao))))\n",
    "                break\n",
    "        if probX > 0:\n",
    "            probLinha.append(probX)\n",
    "        elif probX == 0:\n",
    "            probLinha.append(1/(len(contandoSim)+(len(contandoSim)+len(contandoNao))))\n",
    "    y = 1\n",
    "    for x in probLinha:\n",
    "        y *= x\n",
    "    probAllSIM.append(y)\n",
    "\n",
    "\n",
    "#Calcular a probabilidade de uma frase não ser relevante na planilha teste\n",
    "probAllNAO = []\n",
    "y = 1\n",
    "for i in range(len(planilhaTEST.Teste)):\n",
    "    probLinha = []\n",
    "    for k in range(len(planilhaTEST.Teste[i])):\n",
    "        probX = 0\n",
    "        for j in range(len(contandoNao)):\n",
    "            if contandoNao[j][0] == planilhaTEST.Teste[i][k]:\n",
    "                probX = ((contandoNao[j][1]+1)/(len(contandoNao)+(len(contandoSim)+len(contandoNao))))\n",
    "                break\n",
    "        if probX > 0:\n",
    "            probLinha.append(probX)\n",
    "        elif probX == 0:\n",
    "            probLinha.append(1/(len(contandoNao)+(len(contandoSim)+len(contandoNao))))\n",
    "    y = 1\n",
    "    for x in probLinha:\n",
    "        y *= x\n",
    "    probAllNAO.append(y)\n",
    "\n",
    "#print(probAllSIM)\n",
    "#print('.')\n",
    "#print(probAllNAO)\n",
    "#print('Prob all sim',len(probAllSIM))\n",
    "#print('Prob all nao',len(probAllNAO))\n",
    "\n",
    "#Comapra a probabilidade da palavra ser relevante ou nao e cria uma planilha para isso\n",
    "listaRelevanciaNova = []\n",
    "for i in range(len(probAllSIM)):\n",
    "    if probAllSIM[i]>probAllNAO[i]:\n",
    "        listaRelevanciaNova.append('sim')\n",
    "    elif probAllSIM[i]<probAllNAO[i]:\n",
    "        listaRelevanciaNova.append('não')\n",
    "\n",
    "print(listaRelevanciaNova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relevância Nova calculada</th>\n",
       "      <th>não</th>\n",
       "      <th>sim</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>não</th>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sim</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relevância Nova calculada  não  sim  All\n",
       "Relevancia                              \n",
       "não                         29   37   66\n",
       "sim                          1  133  134\n",
       "All                         30  170  200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilhaTEST['Relevância Nova calculada'] = listaRelevanciaNova\n",
    "ct = pd.crosstab(planilhaTEST['Relevancia'],planilhaTEST['Relevância Nova calculada'], margins=True)\n",
    "#planilhaTREI\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevantes - Classificados Incorretamente 56.060606060606055\n",
      "Relevantes - Classificados Corretamente 99.25373134328358\n",
      "Não relevantes - Classificados Corretamente 43.93939393939394\n",
      "Não relevantes - Classificados Incorretamente 0.7462686567164178\n",
      "% de acertos 81.0\n",
      "% de erros 19.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Relevantes - Classificados Incorretamente\", (37/66)*100)\n",
    "print(\"Relevantes - Classificados Corretamente\", (133/134)*100)\n",
    "print(\"Não relevantes - Classificados Corretamente\", (29/66)*100)\n",
    "print(\"Não relevantes - Classificados Incorretamente\", (1/134)*100)\n",
    "print(\"% de acertos\", ((29+133)/200)*100)\n",
    "print(\"% de erros\", (38/200)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ao observar-se a Crosstab comparativa dos resultados (classificação feita pelos alunos X cálculo pelo dispositivo Naive-Bayes), nota-se uma ótima precisão ao classificar-se as frases que julgamos relevantes (99% de acertos). Contudo, houve um erro expressivamente maior quando analisadas as frases não relevantes: parte dessas frases foram postas como relevantes, sendo que deviam ser classificadas como não-relevantes (56% foram classificadas erroneamente).  \n",
    "\n",
    "Dado que nosso classificador é bem simples (não possuindo processos lógicos de classificação complexos, os quais englobariam uma maior gama de tipos de construção de frases), expressões opostas ao que se realmente pretende dizer (sarcásticas), por exemplo, seriam detectadas como relevantes ao invés do sentido real, irrelevantes e vice-versa. Frases de dupla negação resultariam no mesmo problema: a classificação pelo naive-bayes não chega a um alto nível de interpretação de texto, ou seja, não detectaria que a mensagem na verdade tem um sentido oposto ao qual está escrito. \n",
    "\n",
    "Nosso projeto já demonstrou eficiência na detecção de frases relevantes. Porém, essa detecção ainda está parcialmente desrregulada, classificando parte das frases não relevantes também como relevantes. De qualquer forma, a CrossTab demonstra que os erros totais foram baixos, na casa dos 20%. Algumas iterações na lógica de classificação nos traria resultados ainda mais precisos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alimentar a base de treinamento com o próprio classificador é inútil, pois, se o próprio classificador dá os parâmetros de comparação para o que ele faria nas próximas bases de dados, não haveria diferença qualquer nos critérios de classificação, ou seja, não haveria parâmetros \"reais\", apenas parâmetros criados pelo próprio classificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador Naive-Bayes possui larga aplicação no que se refere a categorização de textos. Então, não está preso a detectar sentimentos, como neste projeto: ele pode ser usado, por exemplo, para detectar textos de spam em relação a e-mails legítmos. \n",
    "Indo mais além, encontra-se utilidade no navegador também na Medicina: o classificador consegue ajudar o profissional a tomar decisões e de forma mais rápida em diagnósticos, tudo isso por meio da probabilidade. \n",
    "Fonte: http://scialert.net/fulltext/?doi=itj.2012.1166.1174&org=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
